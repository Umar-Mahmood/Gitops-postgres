================================================================================
                 POSTGRES OPERATOR DEMO - SUMMARY VERSION
================================================================================

CLUSTER CONNECTION: ssh root@27.100.250.27 -p 6787

================================================================================
PART 1: SETUP VERIFICATION
================================================================================

1.1 CONNECT & VERIFY CLUSTER
-----------------------------
Location: Local Machine
ssh root@27.100.250.27 -p 6787

Location: Cluster
kubectl get nodes
kubectl cluster-info

1.2 CHECK ARGOCD APPLICATIONS
------------------------------
Location: Cluster
# List all ArgoCD apps
kubectl get applications -n argocd

# Check sync status
kubectl get applications -n argocd -o wide

# (Optional) Access ArgoCD UI
kubectl port-forward svc/argocd-server -n argocd 8080:443
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo
# Open: https://localhost:8080 (admin / password-from-above)

1.3 VERIFY OPERATOR & CONTROLLER
---------------------------------
Location: Cluster
# Check postgres operator
kubectl get pods -n postgres-operator
kubectl logs -n postgres-operator deployment/postgres-operator --tail=30

# Check user controller
kubectl get pods -n postgres | grep user-controller
kubectl logs deployment/user-controller -n postgres --tail=30

1.4 CHECK POSTGRES CLUSTER
---------------------------
Location: Cluster
# List postgres clusters
kubectl get postgresql

# Check cluster pods
kubectl get pods -l application=spilo

# Check Patroni status
kubectl exec -it acid-minimal-cluster-0 -- patronictl list


================================================================================
PART 2: CLUSTER CONFIGURATION CHANGES
================================================================================

2.1 VIEW CURRENT CONFIGURATION
-------------------------------
Location: Local Machine
cat /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/postgres-config/postgres-cluster.yaml

2.2 SCALE CLUSTER (3 → 4 instances)
------------------------------------
Location: Local Machine
nano /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/postgres-config/postgres-cluster.yaml
# Change: numberOfInstances: 3 → 4

cd /home/ncl-admin/Desktop/conf-paper
git add zilando-CRDs/postgres-config/postgres-cluster.yaml
git commit -m "Scale cluster to 4 instances"
git push

Location: Cluster
# Watch pods being created
kubectl get pods -l application=spilo -w

# Verify scaling
kubectl exec -it acid-minimal-cluster-0 -- patronictl list

2.3 ADD RESOURCE LIMITS
------------------------
Location: Local Machine
nano /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/postgres-config/postgres-cluster.yaml
# Add under spec:
#   resources:
#     requests:
#       cpu: 500m
#       memory: 500Mi
#     limits:
#       cpu: 1000m
#       memory: 1Gi

git add zilando-CRDs/postgres-config/postgres-cluster.yaml
git commit -m "Add resource limits"
git push

Location: Cluster
kubectl get pods -l application=spilo -o yaml | grep -A 10 resources


================================================================================
PART 3: FAILOVER TESTING
================================================================================

3.1 CREATE TEST DATA
---------------------
Location: Cluster
# Create database and test data
kubectl exec -i acid-minimal-cluster-0 -- bash -lc "psql -U postgres <<'SQL'
CREATE DATABASE failover_test;
\c failover_test
CREATE TABLE customers (id SERIAL PRIMARY KEY, name TEXT, created_at TIMESTAMP DEFAULT NOW());
INSERT INTO customers (name) VALUES ('Alice'), ('Bob'), ('Charlie');
SQL"

# Verify data
kubectl exec -i acid-minimal-cluster-0 -- psql -U postgres -d failover_test -c "TABLE customers;"

3.2 SCENARIO 1: DELETE PRIMARY POD
-----------------------------------
Location: Cluster
# Check current primary
kubectl exec -it acid-minimal-cluster-0 -- patronictl list

# Watch failover (in separate terminal)
kubectl get pods -l application=spilo -w

# Delete primary pod
kubectl delete pod acid-minimal-cluster-0

# Check new leader
kubectl exec -it acid-minimal-cluster-1 -- patronictl list

# Verify data integrity
kubectl exec -i acid-minimal-cluster-1 -- psql -U postgres -d failover_test -c "TABLE customers;"

3.3 SCENARIO 2: MANUAL SWITCHOVER
----------------------------------
Location: Cluster
# Perform switchover
kubectl exec -it acid-minimal-cluster-0 -- patronictl switchover --master acid-minimal-cluster-0 --candidate acid-minimal-cluster-1 --force

# Verify new leader
kubectl exec -it acid-minimal-cluster-0 -- patronictl list

3.4 VERIFY DATA CONSISTENCY
----------------------------
Location: Cluster
# Add data on new primary
kubectl exec -i acid-minimal-cluster-1 -- psql -U postgres -d failover_test -c "INSERT INTO customers (name) VALUES ('Diana'), ('Eve'), ('Frank');"

# Verify on primary
kubectl exec -i acid-minimal-cluster-1 -- psql -U postgres -d failover_test -c "TABLE customers;"

# Wait for replication
sleep 5

# Verify on replica
kubectl exec -i acid-minimal-cluster-2 -- psql -U postgres -d failover_test -c "TABLE customers;"


================================================================================
PART 4: USER AUTOMATION
================================================================================

4.1 CHECK CURRENT USERS
------------------------
Location: Local Machine
cat /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/UserManifests/users.yaml

Location: Cluster
kubectl get postgresqlusers
kubectl exec -i acid-minimal-cluster-0 -- psql -U postgres -d postgres -c "\du"

4.2 ADD NEW USER VIA GITOPS
----------------------------
Location: Local Machine
nano /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/UserManifests/users.yaml

# Add new user:
# ---
# apiVersion: acid.zalan.do/v1
# kind: PostgreSQLUser
# metadata:
#   name: demo-user
#   namespace: default
# spec:
#   cluster: acid-minimal-cluster
#   database: foo
#   username: demo_user
#   privileges:
#     - SELECT
#     - INSERT
#     - UPDATE

cd /home/ncl-admin/Desktop/conf-paper
git add zilando-CRDs/UserManifests/users.yaml
git commit -m "Add demo_user"
git push

Location: Cluster
# Watch controller logs
kubectl logs -f deployment/user-controller -n postgres

# Verify user created
kubectl exec -i acid-minimal-cluster-0 -- psql -U postgres -d postgres -c "\du demo_user"

4.3 UPDATE USER PRIVILEGES
---------------------------
Location: Local Machine
nano /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/UserManifests/users.yaml
# Add DELETE to privileges

git add zilando-CRDs/UserManifests/users.yaml
git commit -m "Update demo_user privileges"
git push

Location: Cluster
# Watch controller apply changes
kubectl logs -f deployment/user-controller -n postgres

# Verify privileges
kubectl exec -i acid-minimal-cluster-0 -- psql -U postgres -d foo -c "
SELECT grantee, privilege_type 
FROM information_schema.role_table_grants 
WHERE grantee = 'demo_user';"

4.4 DELETE USER
---------------
Location: Local Machine
nano /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/UserManifests/users.yaml
# Remove demo-user section

git add zilando-CRDs/UserManifests/users.yaml
git commit -m "Remove demo_user"
git push

Location: Cluster
# Verify user removed
kubectl exec -i acid-minimal-cluster-0 -- psql -U postgres -d postgres -c "\du demo_user"


================================================================================
PART 5: MONITORING
================================================================================

5.1 CHECK CLUSTER HEALTH
-------------------------
Location: Cluster
# Patroni status
kubectl exec -it acid-minimal-cluster-0 -- patronictl list

# Replication status
kubectl exec -i acid-minimal-cluster-0 -- psql -U postgres -d postgres -c "
SELECT client_addr, state, sync_state, replay_lag FROM pg_stat_replication;"

5.2 CHECK LOGS
--------------
Location: Cluster
# Operator logs
kubectl logs -n postgres-operator deployment/postgres-operator --tail=50

# Controller logs
kubectl logs -n postgres deployment/user-controller --tail=50

5.3 CHECK ARGOCD SYNC
---------------------
Location: Cluster
kubectl get applications -n argocd
kubectl describe application postgres-cluster -n argocd


================================================================================
TROUBLESHOOTING
================================================================================

RESTART CONTROLLER
------------------
Location: Cluster
kubectl rollout restart deployment user-controller -n postgres
kubectl rollout status deployment user-controller -n postgres

REBUILD CONTROLLER (if needed)
-------------------------------
Location: Local Machine
cd /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/controller
docker build -t 43911/user-controller:latest .
docker push 43911/user-controller:latest

Location: Cluster
kubectl rollout restart deployment user-controller -n postgres


================================================================================
CLEANUP
================================================================================

Location: Local Machine
# Scale back to 3 instances
nano /home/ncl-admin/Desktop/conf-paper/zilando-CRDs/postgres-config/postgres-cluster.yaml
git add zilando-CRDs/postgres-config/postgres-cluster.yaml
git commit -m "Scale back to 3 instances"
git push

Location: Cluster
# Drop test database
kubectl exec -i acid-minimal-cluster-0 -- psql -U postgres -c "DROP DATABASE failover_test;"


================================================================================
KEY COMMANDS REFERENCE
================================================================================

# Connect
ssh root@27.100.250.27 -p 6787

# Status checks
kubectl get applications -n argocd
kubectl get postgresql
kubectl get postgresqlusers
kubectl get pods -l application=spilo
kubectl exec -it acid-minimal-cluster-0 -- patronictl list

# GitOps workflow
git add <files>
git commit -m "message"
git push

# Monitor
kubectl logs -f deployment/user-controller -n postgres
kubectl logs -n postgres-operator deployment/postgres-operator --tail=50

# Database access
kubectl exec -it acid-minimal-cluster-0 -- psql -U postgres -d postgres

================================================================================
